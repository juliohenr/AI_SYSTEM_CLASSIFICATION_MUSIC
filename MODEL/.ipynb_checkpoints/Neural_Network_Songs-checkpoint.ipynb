{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from unicodedata import normalize as norm\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento das Musicas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "funk = pd.read_csv('funk.csv')\n",
    "bossa_nova = pd.read_csv('bossa_nova.csv')\n",
    "gospel = pd.read_csv('gospel.csv')\n",
    "sertanejo = pd.read_csv('sertanejo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "funk['label'] = 'funk'\n",
    "bossa_nova['label'] = 'bossa nova'\n",
    "gospel['label'] = 'gospel'\n",
    "sertanejo['label'] = 'sertanejo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([funk,bossa_nova,gospel,sertanejo])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da volumetria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bossa nova</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funk</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gospel</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sertanejo</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lyric\n",
       "label            \n",
       "bossa nova    800\n",
       "funk          800\n",
       "gospel        800\n",
       "sertanejo     800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('label').count().sort_values(by=['lyric'],ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré - processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TEXTO_CLEAN'] = dataset['lyric'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para contar o número de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_words(text):\n",
    "\n",
    "    quantity_of_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_words = [i for i in quantity_of_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_words = len(quantity_of_words)\n",
    "\n",
    "    return quantity_of_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"COUNT_TOKENS\"] = dataset[\"TEXTO_CLEAN\"].apply(lambda x: calculate_number_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_TOKENS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bossa nova</td>\n",
       "      <td>88.42125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funk</td>\n",
       "      <td>150.65250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gospel</td>\n",
       "      <td>102.59750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sertanejo</td>\n",
       "      <td>102.90000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            COUNT_TOKENS\n",
       "label                   \n",
       "bossa nova      88.42125\n",
       "funk           150.65250\n",
       "gospel         102.59750\n",
       "sertanejo      102.90000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para contar o número de tokens diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_number_diferent_words(text):\n",
    "\n",
    "    quantity_of_diferent_words = text.split(\" \")\n",
    "\n",
    "    quantity_of_diferent_words = [i for i in quantity_of_diferent_words if i!=\"\"]\n",
    "\n",
    "    quantity_of_diferent_words = set(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = list(quantity_of_diferent_words)\n",
    "\n",
    "    quantity_of_diferent_words = len(quantity_of_diferent_words)\n",
    "\n",
    "    return quantity_of_diferent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"COUNT_DIFERENT_TOKENS\"] = dataset[\"TEXTO_CLEAN\"].apply(lambda x: calculate_number_diferent_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COUNT_TOKENS</th>\n",
       "      <th>COUNT_DIFERENT_TOKENS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bossa nova</td>\n",
       "      <td>88.42125</td>\n",
       "      <td>53.03250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funk</td>\n",
       "      <td>150.65250</td>\n",
       "      <td>65.67625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gospel</td>\n",
       "      <td>102.59750</td>\n",
       "      <td>51.30750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sertanejo</td>\n",
       "      <td>102.90000</td>\n",
       "      <td>54.72125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            COUNT_TOKENS  COUNT_DIFERENT_TOKENS\n",
       "label                                          \n",
       "bossa nova      88.42125               53.03250\n",
       "funk           150.65250               65.67625\n",
       "gospel         102.59750               51.30750\n",
       "sertanejo      102.90000               54.72125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "      <th>TEXTO_CLEAN</th>\n",
       "      <th>COUNT_TOKENS</th>\n",
       "      <th>COUNT_DIFERENT_TOKENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\nMaria! Maria!\\nOw, Maria!\\nEstoy enamorado ...</td>\n",
       "      <td>funk</td>\n",
       "      <td>maria maria ow maria estoy enamorado  ti mari...</td>\n",
       "      <td>214</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\n[Nego do Borel]\\nVocê partiu meu coração, a...</td>\n",
       "      <td>funk</td>\n",
       "      <td>nego  borel voce partiu  coracao ai   amor na...</td>\n",
       "      <td>221</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nHi! My name is Lan\\nVou dar game over\\nNo s...</td>\n",
       "      <td>funk</td>\n",
       "      <td>hi my name is lan vou dar game over   cu novi...</td>\n",
       "      <td>264</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nÉ o novo hit do verão\\nPra geral curtir\\nEl...</td>\n",
       "      <td>funk</td>\n",
       "      <td>novo hit  verao pra geral curtir  joga  bum...</td>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\nÉ a flauta envolvente que mexe com a mente\\...</td>\n",
       "      <td>funk</td>\n",
       "      <td>flauta envolvente  mexe   mente   ta presen...</td>\n",
       "      <td>124</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>\\nA luta chegou de repente\\nE te colocou fren...</td>\n",
       "      <td>sertanejo</td>\n",
       "      <td>luta chegou  repente   colocou frente  frent...</td>\n",
       "      <td>126</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>\\nPara de mentir pra você mesmo\\nSeu amor por...</td>\n",
       "      <td>sertanejo</td>\n",
       "      <td>mentir pra voce   amor  mim nao  segredo  a...</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>\\nQuadros nunca esquecem e sempre contarão\\nO...</td>\n",
       "      <td>sertanejo</td>\n",
       "      <td>quadros nunca esquecem  sempre contarao   aco...</td>\n",
       "      <td>120</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>\\nVoltei era de madrugada e me assustei\\nAs l...</td>\n",
       "      <td>sertanejo</td>\n",
       "      <td>voltei   madrugada   assustei  luzes  acesas ...</td>\n",
       "      <td>87</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>\\nA gente fala, fala, fala e não diz nada\\nNa...</td>\n",
       "      <td>sertanejo</td>\n",
       "      <td>gente fala fala fala  nao diz nada  verdade ...</td>\n",
       "      <td>163</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyric      label  \\\n",
       "0     \\nMaria! Maria!\\nOw, Maria!\\nEstoy enamorado ...       funk   \n",
       "1     \\n[Nego do Borel]\\nVocê partiu meu coração, a...       funk   \n",
       "2     \\nHi! My name is Lan\\nVou dar game over\\nNo s...       funk   \n",
       "3     \\nÉ o novo hit do verão\\nPra geral curtir\\nEl...       funk   \n",
       "4     \\nÉ a flauta envolvente que mexe com a mente\\...       funk   \n",
       "..                                                 ...        ...   \n",
       "795   \\nA luta chegou de repente\\nE te colocou fren...  sertanejo   \n",
       "796   \\nPara de mentir pra você mesmo\\nSeu amor por...  sertanejo   \n",
       "797   \\nQuadros nunca esquecem e sempre contarão\\nO...  sertanejo   \n",
       "798   \\nVoltei era de madrugada e me assustei\\nAs l...  sertanejo   \n",
       "799   \\nA gente fala, fala, fala e não diz nada\\nNa...  sertanejo   \n",
       "\n",
       "                                           TEXTO_CLEAN  COUNT_TOKENS  \\\n",
       "0     maria maria ow maria estoy enamorado  ti mari...           214   \n",
       "1     nego  borel voce partiu  coracao ai   amor na...           221   \n",
       "2     hi my name is lan vou dar game over   cu novi...           264   \n",
       "3       novo hit  verao pra geral curtir  joga  bum...            60   \n",
       "4       flauta envolvente  mexe   mente   ta presen...           124   \n",
       "..                                                 ...           ...   \n",
       "795    luta chegou  repente   colocou frente  frent...           126   \n",
       "796     mentir pra voce   amor  mim nao  segredo  a...            58   \n",
       "797   quadros nunca esquecem  sempre contarao   aco...           120   \n",
       "798   voltei   madrugada   assustei  luzes  acesas ...            87   \n",
       "799    gente fala fala fala  nao diz nada  verdade ...           163   \n",
       "\n",
       "     COUNT_DIFERENT_TOKENS  \n",
       "0                       28  \n",
       "1                       89  \n",
       "2                      100  \n",
       "3                       42  \n",
       "4                       22  \n",
       "..                     ...  \n",
       "795                     63  \n",
       "796                     41  \n",
       "797                     39  \n",
       "798                     78  \n",
       "799                     41  \n",
       "\n",
       "[3200 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset['TEXTO_CLEAN'].values, dataset['label'].values, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_converted = tokenizer.texts_to_matrix(x_train,mode='tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_label = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_label.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_converted = encode_label.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_converted = encode_label.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1792 samples, validate on 448 samples\n",
      "Epoch 1/100\n",
      "1792/1792 [==============================] - 1s 627us/sample - loss: 1.0612 - accuracy: 0.5938 - val_loss: 0.7166 - val_accuracy: 0.7768\n",
      "Epoch 2/100\n",
      "1792/1792 [==============================] - 0s 142us/sample - loss: 0.3227 - accuracy: 0.9425 - val_loss: 0.5343 - val_accuracy: 0.8304\n",
      "Epoch 3/100\n",
      "1792/1792 [==============================] - 0s 124us/sample - loss: 0.1248 - accuracy: 0.9844 - val_loss: 0.4716 - val_accuracy: 0.8326\n",
      "Epoch 4/100\n",
      "1792/1792 [==============================] - 0s 109us/sample - loss: 0.0721 - accuracy: 0.9950 - val_loss: 0.4652 - val_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0451 - accuracy: 0.9961 - val_loss: 0.4682 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0281 - accuracy: 0.9972 - val_loss: 0.4687 - val_accuracy: 0.8371\n",
      "Epoch 7/100\n",
      "1792/1792 [==============================] - 0s 106us/sample - loss: 0.0252 - accuracy: 0.9972 - val_loss: 0.4827 - val_accuracy: 0.8371\n",
      "Epoch 8/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0201 - accuracy: 0.9972 - val_loss: 0.4759 - val_accuracy: 0.8393\n",
      "Epoch 9/100\n",
      "1792/1792 [==============================] - 0s 128us/sample - loss: 0.0162 - accuracy: 0.9978 - val_loss: 0.4761 - val_accuracy: 0.8393\n",
      "Epoch 10/100\n",
      "1792/1792 [==============================] - 0s 113us/sample - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.4895 - val_accuracy: 0.8415\n",
      "Epoch 11/100\n",
      "1792/1792 [==============================] - 0s 133us/sample - loss: 0.0133 - accuracy: 0.9978 - val_loss: 0.4866 - val_accuracy: 0.8393\n",
      "Epoch 12/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0147 - accuracy: 0.9961 - val_loss: 0.4878 - val_accuracy: 0.8415\n",
      "Epoch 13/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.5059 - val_accuracy: 0.8438\n",
      "Epoch 14/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.4996 - val_accuracy: 0.8460\n",
      "Epoch 15/100\n",
      "1792/1792 [==============================] - 0s 114us/sample - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.5169 - val_accuracy: 0.8504\n",
      "Epoch 16/100\n",
      "1792/1792 [==============================] - 0s 125us/sample - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.5103 - val_accuracy: 0.8371\n",
      "Epoch 17/100\n",
      "1792/1792 [==============================] - 0s 104us/sample - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.5161 - val_accuracy: 0.8438\n",
      "Epoch 18/100\n",
      "1792/1792 [==============================] - 0s 104us/sample - loss: 0.0050 - accuracy: 0.9989 - val_loss: 0.5280 - val_accuracy: 0.8504\n",
      "Epoch 19/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.5170 - val_accuracy: 0.8504\n",
      "Epoch 20/100\n",
      "1792/1792 [==============================] - 0s 107us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.5214 - val_accuracy: 0.8415\n",
      "Epoch 21/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.5348 - val_accuracy: 0.8527\n",
      "Epoch 22/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0068 - accuracy: 0.9989 - val_loss: 0.5210 - val_accuracy: 0.8527\n",
      "Epoch 23/100\n",
      "1792/1792 [==============================] - 0s 139us/sample - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.5253 - val_accuracy: 0.8482\n",
      "Epoch 24/100\n",
      "1792/1792 [==============================] - 0s 110us/sample - loss: 0.0092 - accuracy: 0.9978 - val_loss: 0.5251 - val_accuracy: 0.8482\n",
      "Epoch 25/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0094 - accuracy: 0.9972 - val_loss: 0.5366 - val_accuracy: 0.8482\n",
      "Epoch 26/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.5304 - val_accuracy: 0.8504\n",
      "Epoch 27/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.5538 - val_accuracy: 0.8460\n",
      "Epoch 28/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0078 - accuracy: 0.9989 - val_loss: 0.5325 - val_accuracy: 0.8482\n",
      "Epoch 29/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.5525 - val_accuracy: 0.8482\n",
      "Epoch 30/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.5441 - val_accuracy: 0.8438\n",
      "Epoch 31/100\n",
      "1792/1792 [==============================] - 0s 108us/sample - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.5363 - val_accuracy: 0.8438\n",
      "Epoch 32/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.5532 - val_accuracy: 0.8482\n",
      "Epoch 33/100\n",
      "1792/1792 [==============================] - 0s 104us/sample - loss: 0.0055 - accuracy: 0.9978 - val_loss: 0.5502 - val_accuracy: 0.8460\n",
      "Epoch 34/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.5528 - val_accuracy: 0.8482\n",
      "Epoch 35/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.5520 - val_accuracy: 0.8504\n",
      "Epoch 36/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0061 - accuracy: 0.9978 - val_loss: 0.5525 - val_accuracy: 0.8527\n",
      "Epoch 37/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.5562 - val_accuracy: 0.8504\n",
      "Epoch 38/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.5597 - val_accuracy: 0.8460\n",
      "Epoch 39/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.5653 - val_accuracy: 0.8438\n",
      "Epoch 40/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.5559 - val_accuracy: 0.8438\n",
      "Epoch 41/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.5722 - val_accuracy: 0.8393\n",
      "Epoch 42/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.5640 - val_accuracy: 0.8460\n",
      "Epoch 43/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.5621 - val_accuracy: 0.8438\n",
      "Epoch 44/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.5779 - val_accuracy: 0.8393\n",
      "Epoch 45/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.5663 - val_accuracy: 0.8438\n",
      "Epoch 46/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.5685 - val_accuracy: 0.8438\n",
      "Epoch 47/100\n",
      "1792/1792 [==============================] - 0s 124us/sample - loss: 0.0045 - accuracy: 0.9978 - val_loss: 0.5794 - val_accuracy: 0.8393\n",
      "Epoch 48/100\n",
      "1792/1792 [==============================] - 0s 116us/sample - loss: 0.0025 - accuracy: 0.9983 - val_loss: 0.5708 - val_accuracy: 0.8415\n",
      "Epoch 49/100\n",
      "1792/1792 [==============================] - 0s 123us/sample - loss: 0.0048 - accuracy: 0.9989 - val_loss: 0.5924 - val_accuracy: 0.8393\n",
      "Epoch 50/100\n",
      "1792/1792 [==============================] - 0s 105us/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.5730 - val_accuracy: 0.8393\n",
      "Epoch 51/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.5768 - val_accuracy: 0.8393\n",
      "Epoch 52/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.5997 - val_accuracy: 0.8393\n",
      "Epoch 53/100\n",
      "1792/1792 [==============================] - 0s 111us/sample - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.5927 - val_accuracy: 0.8393\n",
      "Epoch 54/100\n",
      "1792/1792 [==============================] - 0s 139us/sample - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.5925 - val_accuracy: 0.8348\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792/1792 [==============================] - 0s 105us/sample - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.5819 - val_accuracy: 0.8393\n",
      "Epoch 56/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.5832 - val_accuracy: 0.8371\n",
      "Epoch 57/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.5951 - val_accuracy: 0.8415\n",
      "Epoch 58/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.5917 - val_accuracy: 0.8460\n",
      "Epoch 59/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.5940 - val_accuracy: 0.8393\n",
      "Epoch 60/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0026 - accuracy: 0.9983 - val_loss: 0.6108 - val_accuracy: 0.8348\n",
      "Epoch 61/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.6027 - val_accuracy: 0.8348\n",
      "Epoch 62/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.6040 - val_accuracy: 0.8348\n",
      "Epoch 63/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.5927 - val_accuracy: 0.8415\n",
      "Epoch 64/100\n",
      "1792/1792 [==============================] - 0s 110us/sample - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.5928 - val_accuracy: 0.8393\n",
      "Epoch 65/100\n",
      "1792/1792 [==============================] - 0s 127us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6041 - val_accuracy: 0.8348\n",
      "Epoch 66/100\n",
      "1792/1792 [==============================] - 0s 127us/sample - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.5954 - val_accuracy: 0.8393\n",
      "Epoch 67/100\n",
      "1792/1792 [==============================] - 0s 114us/sample - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.5954 - val_accuracy: 0.8393\n",
      "Epoch 68/100\n",
      "1792/1792 [==============================] - 0s 147us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6081 - val_accuracy: 0.8393\n",
      "Epoch 69/100\n",
      "1792/1792 [==============================] - 0s 116us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.6039 - val_accuracy: 0.8348\n",
      "Epoch 70/100\n",
      "1792/1792 [==============================] - 0s 115us/sample - loss: 0.0034 - accuracy: 0.9983 - val_loss: 0.5973 - val_accuracy: 0.8348\n",
      "Epoch 71/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0038 - accuracy: 0.9983 - val_loss: 0.6042 - val_accuracy: 0.8371\n",
      "Epoch 72/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6113 - val_accuracy: 0.8371\n",
      "Epoch 73/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6045 - val_accuracy: 0.8371\n",
      "Epoch 74/100\n",
      "1792/1792 [==============================] - 0s 123us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6076 - val_accuracy: 0.8371\n",
      "Epoch 75/100\n",
      "1792/1792 [==============================] - 0s 105us/sample - loss: 0.0091 - accuracy: 0.9983 - val_loss: 0.6079 - val_accuracy: 0.8348\n",
      "Epoch 76/100\n",
      "1792/1792 [==============================] - 0s 129us/sample - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.6100 - val_accuracy: 0.8348\n",
      "Epoch 77/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0042 - accuracy: 0.9983 - val_loss: 0.6167 - val_accuracy: 0.8348\n",
      "Epoch 78/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.6083 - val_accuracy: 0.8415\n",
      "Epoch 79/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 0.0031 - accuracy: 0.9983 - val_loss: 0.6250 - val_accuracy: 0.8348\n",
      "Epoch 80/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0048 - accuracy: 0.9978 - val_loss: 0.6238 - val_accuracy: 0.8393\n",
      "Epoch 81/100\n",
      "1792/1792 [==============================] - 0s 118us/sample - loss: 0.0037 - accuracy: 0.9978 - val_loss: 0.6182 - val_accuracy: 0.8348\n",
      "Epoch 82/100\n",
      "1792/1792 [==============================] - 0s 129us/sample - loss: 0.0018 - accuracy: 0.9989 - val_loss: 0.6211 - val_accuracy: 0.8371\n",
      "Epoch 83/100\n",
      "1792/1792 [==============================] - 0s 113us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.6236 - val_accuracy: 0.8393\n",
      "Epoch 84/100\n",
      "1792/1792 [==============================] - 0s 114us/sample - loss: 0.0032 - accuracy: 0.9983 - val_loss: 0.6316 - val_accuracy: 0.8348\n",
      "Epoch 85/100\n",
      "1792/1792 [==============================] - 0s 116us/sample - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.6285 - val_accuracy: 0.8393\n",
      "Epoch 86/100\n",
      "1792/1792 [==============================] - 0s 116us/sample - loss: 0.0033 - accuracy: 0.9983 - val_loss: 0.6233 - val_accuracy: 0.8415\n",
      "Epoch 87/100\n",
      "1792/1792 [==============================] - 0s 113us/sample - loss: 0.0029 - accuracy: 0.9983 - val_loss: 0.6337 - val_accuracy: 0.8348\n",
      "Epoch 88/100\n",
      "1792/1792 [==============================] - 0s 115us/sample - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.6322 - val_accuracy: 0.8393\n",
      "Epoch 89/100\n",
      "1792/1792 [==============================] - 0s 118us/sample - loss: 0.0029 - accuracy: 0.9978 - val_loss: 0.6301 - val_accuracy: 0.8415\n",
      "Epoch 90/100\n",
      "1792/1792 [==============================] - 0s 117us/sample - loss: 0.0031 - accuracy: 0.9983 - val_loss: 0.6417 - val_accuracy: 0.8393\n",
      "Epoch 91/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0028 - accuracy: 0.9983 - val_loss: 0.6338 - val_accuracy: 0.8415\n",
      "Epoch 92/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0047 - accuracy: 0.9978 - val_loss: 0.6510 - val_accuracy: 0.8393\n",
      "Epoch 93/100\n",
      "1792/1792 [==============================] - 0s 112us/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6627 - val_accuracy: 0.8326\n",
      "Epoch 94/100\n",
      "1792/1792 [==============================] - 0s 109us/sample - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.6544 - val_accuracy: 0.8393\n",
      "Epoch 95/100\n",
      "1792/1792 [==============================] - 0s 106us/sample - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.6561 - val_accuracy: 0.8415\n",
      "Epoch 96/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.6625 - val_accuracy: 0.8304\n",
      "Epoch 97/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.6531 - val_accuracy: 0.8460\n",
      "Epoch 98/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.6638 - val_accuracy: 0.8438\n",
      "Epoch 99/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 0.0045 - accuracy: 0.9978 - val_loss: 0.6573 - val_accuracy: 0.8438\n",
      "Epoch 100/100\n",
      "1792/1792 [==============================] - 0s 109us/sample - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.6530 - val_accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f43d41d6690>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_converted,y_train_converted,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_converted = tokenizer.texts_to_matrix(x_test,mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(x_teste_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = [np.argmax(predict[i]) for i in range(len(predict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = encode_label.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_teste_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  bossa nova       0.84      0.75      0.79       254\n",
      "        funk       0.95      0.84      0.89       238\n",
      "      gospel       0.88      0.93      0.91       242\n",
      "   sertanejo       0.68      0.81      0.74       226\n",
      "\n",
      "    accuracy                           0.83       960\n",
      "   macro avg       0.84      0.83      0.83       960\n",
      "weighted avg       0.84      0.83      0.83       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência do Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência do Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(encode_label, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'rb') as handle:\n",
    "\n",
    "    encode_label = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frases de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funk1 = \"Ela só quer curtir Ela só quer zuar Gosta de dançar Dançar, dançar Se o papo for balada\\nNão deixa pra depois Solteira de carteirinha\"\n",
    "funk2 = \"Eu te amava no tempo da escola Mas você não me dava atenção\\nPedi uma chance, até duas Mas você só me disse não\\nMas você só me disse não Mas você só me disse não Mas com o tempo eu parei e fiz essa canção\\nVou marcar de te ver e não ir\"\n",
    "\n",
    "gospel1 = \"Senhor, meu Deus, quando eu, maravilhado Contemplo a tua imensa criação A terra e o mar e o céu todo estrelado Me vêm falar da tua perfeição Então minh'alma canta a ti\"\n",
    "gospel2 = \" A dor não mata se Deus está presente Só quem caminha com Ele entende o valor De uma lágrima derramada no altar da dor Enxugada pelas mãos do consolador Se Ele quiser, Ele ressuscita mortos\\nEle faz o impossível Tudo porque Ele é Deus Mas se Ele não quer que aconteça do meu jeito Eu declaro que eu aceito\\nE agora o milagre sou eu, sou eu O milagre sou eu, sou eu Eu não vou parar\"\n",
    "\n",
    "sertanejo1 = \"\\nVocê pode ficar com quem você quiser\\nNão tem nada a ver\\nEu não mando em você\\nMas ainda choro\\nE quando alguém comenta não quero saber\\nMe preocupo e apesar dos pesares\\nEu sempre quero te ver bem\\nE ainda vou além\\nEm uma relação\\nSei que não vai ser fácil amar outro alguém\"\n",
    "sertanejo2 = '\\nContando, são 126 cabides\\nE no guarda-roupa, um grande espaço seu\\nDeixado\\nO que faço? Estou eu bem no meu canto\\nFuturo levado meu\\nRoubado\\nTô negociando com a solidão\\nTô tentando convencer que ela não fique, não\\nSe vá\\nTô eu negociando com a solidão\\nSó me cobre esse juros no final da outra estação\\nE se vá\\nEu nem quis te ver de malas prontas\\nLevando o que eu temia\\nSuas roupas e minha alegria\\nE eu nem quis te ver de malas prontas\\nNós dois não mais existe'\n",
    "\n",
    "bossa_nova1 = 'Um cantinho e um violão\\nEste amor, uma canção\\nPra fazer feliz a quem se ama\\nMuita calma pra pensar\\nE ter tempo pra sonhar\\nDa janela vê-se o Corcovado\\nO Redentor que lindo'\n",
    "bossa_nova2 = 'Vai tua vida\\nTeu caminho é de paz e amor\\nA tua vida\\nÉ uma linda canção de amor\\nAbre os teus braços e canta\\nA última esperança\\nA esperança divina\\nDe amar em paz\\nSe todos fossem\\nIguais a você\\nQue maravilha viver\\nUma canção pelo ar\\nUma mulher'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_cleaner(bossa_nova1)\n",
    "\n",
    "sample_converted = tokenizer.texts_to_matrix([text],mode='tfidf')\n",
    "\n",
    "predict = model.predict(sample_converted)\n",
    "\n",
    "predict = np.argmax(predict[0])\n",
    "\n",
    "predict = encode_label.inverse_transform([predict])\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TextExplainer(random_state=42)\n",
    "te.fit(\"Senhor, meu Deus, quando eu, maravilhado Contemplo a tua imensa criação A terra e o mar e o céu todo estrelado Me vêm falar da tua perfeição Então minh'alma canta a ti\", model.predict_proba)\n",
    "te.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_tf = LimeTextExplainer(class_names=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funk1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer_tf.explain_instance(funk1,  model.predict, num_features=4, top_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
