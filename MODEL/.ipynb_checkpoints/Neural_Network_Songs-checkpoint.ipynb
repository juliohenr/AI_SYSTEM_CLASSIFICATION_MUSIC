{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from unicodedata import normalize as norm\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from eli5.lime import TextExplainer\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eli5.lime.lime.TextExplainer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento das Musicas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'sertanejo.csv' does not exist: b'sertanejo.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-946cee5779ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbossa_nova\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bossa_nova.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgospel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gospel.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msertanejo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sertanejo.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'sertanejo.csv' does not exist: b'sertanejo.csv'"
     ]
    }
   ],
   "source": [
    "funk = pd.read_csv('funk.csv')\n",
    "bossa_nova = pd.read_csv('bossa_nova.csv')\n",
    "gospel = pd.read_csv('gospel.csv')\n",
    "sertanejo = pd.read_csv('sertanejo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sertanejo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-77cfec812949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbossa_nova\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bossa nova'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgospel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gospel'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msertanejo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sertanejo'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sertanejo' is not defined"
     ]
    }
   ],
   "source": [
    "funk['label'] = 'funk'\n",
    "bossa_nova['label'] = 'bossa nova'\n",
    "gospel['label'] = 'gospel'\n",
    "sertanejo['label'] = 'sertanejo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([funk,bossa_nova,gospel,sertanejo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\nMaria! Maria!\\nOw, Maria!\\nEstoy enamorado ...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\n[Nego do Borel]\\nVocê partiu meu coração, a...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nHi! My name is Lan\\nVou dar game over\\nNo s...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nÉ o novo hit do verão\\nPra geral curtir\\nEl...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\nÉ a flauta envolvente que mexe com a mente\\...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>\\nA luta chegou de repente\\nE te colocou fren...</td>\n",
       "      <td>sertanejo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>\\nPara de mentir pra você mesmo\\nSeu amor por...</td>\n",
       "      <td>sertanejo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>\\nQuadros nunca esquecem e sempre contarão\\nO...</td>\n",
       "      <td>sertanejo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>\\nVoltei era de madrugada e me assustei\\nAs l...</td>\n",
       "      <td>sertanejo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>\\nA gente fala, fala, fala e não diz nada\\nNa...</td>\n",
       "      <td>sertanejo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyric      label\n",
       "0     \\nMaria! Maria!\\nOw, Maria!\\nEstoy enamorado ...       funk\n",
       "1     \\n[Nego do Borel]\\nVocê partiu meu coração, a...       funk\n",
       "2     \\nHi! My name is Lan\\nVou dar game over\\nNo s...       funk\n",
       "3     \\nÉ o novo hit do verão\\nPra geral curtir\\nEl...       funk\n",
       "4     \\nÉ a flauta envolvente que mexe com a mente\\...       funk\n",
       "..                                                 ...        ...\n",
       "795   \\nA luta chegou de repente\\nE te colocou fren...  sertanejo\n",
       "796   \\nPara de mentir pra você mesmo\\nSeu amor por...  sertanejo\n",
       "797   \\nQuadros nunca esquecem e sempre contarão\\nO...  sertanejo\n",
       "798   \\nVoltei era de madrugada e me assustei\\nAs l...  sertanejo\n",
       "799   \\nA gente fala, fala, fala e não diz nada\\nNa...  sertanejo\n",
       "\n",
       "[3200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\nMaria! Maria!\\nOw, Maria!\\nEstoy enamorado ...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\n[Nego do Borel]\\nVocê partiu meu coração, a...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nHi! My name is Lan\\nVou dar game over\\nNo s...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nÉ o novo hit do verão\\nPra geral curtir\\nEl...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\nÉ a flauta envolvente que mexe com a mente\\...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795</td>\n",
       "      <td>\\nNova moda que pegou\\nJá estourou em São Pau...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>796</td>\n",
       "      <td>\\nSenhor, me proteja de todo o mal\\nQue os in...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>\\nSe até jesus chorou\\nEntão porque que eu\\nN...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>798</td>\n",
       "      <td>\\nFarra, noitada\\nÉ tudo pra essas meninas\\nN...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>799</td>\n",
       "      <td>\\nRAPAZES DA VIGAIRADA\\nOIÇAM BEM COM ATENÇÃO...</td>\n",
       "      <td>funk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lyric label\n",
       "0     \\nMaria! Maria!\\nOw, Maria!\\nEstoy enamorado ...  funk\n",
       "1     \\n[Nego do Borel]\\nVocê partiu meu coração, a...  funk\n",
       "2     \\nHi! My name is Lan\\nVou dar game over\\nNo s...  funk\n",
       "3     \\nÉ o novo hit do verão\\nPra geral curtir\\nEl...  funk\n",
       "4     \\nÉ a flauta envolvente que mexe com a mente\\...  funk\n",
       "..                                                 ...   ...\n",
       "795   \\nNova moda que pegou\\nJá estourou em São Pau...  funk\n",
       "796   \\nSenhor, me proteja de todo o mal\\nQue os in...  funk\n",
       "797   \\nSe até jesus chorou\\nEntão porque que eu\\nN...  funk\n",
       "798   \\nFarra, noitada\\nÉ tudo pra essas meninas\\nN...  funk\n",
       "799   \\nRAPAZES DA VIGAIRADA\\nOIÇAM BEM COM ATENÇÃO...  funk\n",
       "\n",
       "[800 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da volumetria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>bossa nova</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>funk</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gospel</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sertanejo</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lyric\n",
       "label            \n",
       "bossa nova    800\n",
       "funk          800\n",
       "gospel        800\n",
       "sertanejo     800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('label').count().sort_values(by=['lyric'],ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré - processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    #nltk_stopwords = stopwords.words('portuguese')\n",
    "\n",
    "    collection_text = [ {\"text\" : text}]\n",
    "    text = pd.DataFrame(collection_text)\n",
    "\n",
    "    text['text'] = text['text'].astype('str')\n",
    "    text['text'] = text['text'].str.lower()\n",
    "    text['text'] = text['text'].str.replace('\\n',' ')\n",
    "    text['text'] = text['text'].str.replace('\\r',' ')\n",
    "    text['text'] = text['text'].apply(lambda x: norm('NFKD', x).encode('ascii', 'ignore').decode())\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'[^a-zA-Z0-9]',' ',x))\n",
    "    text['text'] = text['text'].apply(lambda x: re.sub(r'\\s+',' ',x))\n",
    "    #pat = r'\\b(?:{})\\b'.format('|'.join(nltk_stopwords))\n",
    "    #text['text'] = text['text'].str.replace(pat,'')\n",
    "    text = text['text'].values[0]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['TEXTO_CLEAN'] = dataset['lyric'].apply(lambda x: text_cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(dataset['TEXTO_CLEAN'].values, dataset['label'].values, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação do TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_converted = tokenizer.texts_to_matrix(x_train,mode='tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_label = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_label.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_converted = encode_label.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_converted = encode_label.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1792 samples, validate on 448 samples\n",
      "Epoch 1/100\n",
      "1792/1792 [==============================] - 2s 850us/sample - loss: 1.1007 - accuracy: 0.5273 - val_loss: 0.7944 - val_accuracy: 0.7567\n",
      "Epoch 2/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.3284 - accuracy: 0.9347 - val_loss: 0.5501 - val_accuracy: 0.8259\n",
      "Epoch 3/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0949 - accuracy: 0.9877 - val_loss: 0.5363 - val_accuracy: 0.8326\n",
      "Epoch 4/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0440 - accuracy: 0.9944 - val_loss: 0.5265 - val_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0265 - accuracy: 0.9978 - val_loss: 0.5478 - val_accuracy: 0.8393\n",
      "Epoch 6/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0176 - accuracy: 0.9978 - val_loss: 0.5523 - val_accuracy: 0.8393\n",
      "Epoch 7/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0119 - accuracy: 0.9994 - val_loss: 0.5654 - val_accuracy: 0.8393\n",
      "Epoch 8/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0104 - accuracy: 0.9983 - val_loss: 0.5728 - val_accuracy: 0.8371\n",
      "Epoch 9/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.5764 - val_accuracy: 0.8415\n",
      "Epoch 10/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0079 - accuracy: 0.9989 - val_loss: 0.5849 - val_accuracy: 0.8371\n",
      "Epoch 11/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.6015 - val_accuracy: 0.8304\n",
      "Epoch 12/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.6009 - val_accuracy: 0.8348\n",
      "Epoch 13/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0045 - accuracy: 0.9994 - val_loss: 0.6088 - val_accuracy: 0.8304\n",
      "Epoch 14/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.6120 - val_accuracy: 0.8348\n",
      "Epoch 15/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.6178 - val_accuracy: 0.8371\n",
      "Epoch 16/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6241 - val_accuracy: 0.8326\n",
      "Epoch 17/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.6300 - val_accuracy: 0.8304\n",
      "Epoch 18/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6359 - val_accuracy: 0.8326\n",
      "Epoch 19/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.8348\n",
      "Epoch 20/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6486 - val_accuracy: 0.8326\n",
      "Epoch 21/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6497 - val_accuracy: 0.8326\n",
      "Epoch 22/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.6558 - val_accuracy: 0.8348\n",
      "Epoch 23/100\n",
      "1792/1792 [==============================] - 0s 102us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.6630 - val_accuracy: 0.8326\n",
      "Epoch 24/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0019 - accuracy: 0.9989 - val_loss: 0.6679 - val_accuracy: 0.8348\n",
      "Epoch 25/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.6754 - val_accuracy: 0.8304\n",
      "Epoch 26/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6754 - val_accuracy: 0.8348\n",
      "Epoch 27/100\n",
      "1792/1792 [==============================] - 0s 107us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.6819 - val_accuracy: 0.8304\n",
      "Epoch 28/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.6848 - val_accuracy: 0.8281\n",
      "Epoch 29/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.6883 - val_accuracy: 0.8326\n",
      "Epoch 30/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6942 - val_accuracy: 0.8304\n",
      "Epoch 31/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.6974 - val_accuracy: 0.8326\n",
      "Epoch 32/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.7017 - val_accuracy: 0.8304\n",
      "Epoch 33/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 8.4447e-04 - accuracy: 1.0000 - val_loss: 0.7053 - val_accuracy: 0.8281\n",
      "Epoch 34/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 6.5137e-04 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.8281\n",
      "Epoch 35/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 5.7768e-04 - accuracy: 1.0000 - val_loss: 0.7163 - val_accuracy: 0.8326\n",
      "Epoch 36/100\n",
      "1792/1792 [==============================] - 0s 108us/sample - loss: 5.5276e-04 - accuracy: 1.0000 - val_loss: 0.7183 - val_accuracy: 0.8304\n",
      "Epoch 37/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 5.3729e-04 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.8304\n",
      "Epoch 38/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 5.1256e-04 - accuracy: 1.0000 - val_loss: 0.7256 - val_accuracy: 0.8281\n",
      "Epoch 39/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 5.0218e-04 - accuracy: 1.0000 - val_loss: 0.7284 - val_accuracy: 0.8304\n",
      "Epoch 40/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 4.5408e-04 - accuracy: 1.0000 - val_loss: 0.7329 - val_accuracy: 0.8304\n",
      "Epoch 41/100\n",
      "1792/1792 [==============================] - 0s 101us/sample - loss: 4.9892e-04 - accuracy: 1.0000 - val_loss: 0.7347 - val_accuracy: 0.8281\n",
      "Epoch 42/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 4.3719e-04 - accuracy: 1.0000 - val_loss: 0.7380 - val_accuracy: 0.8304\n",
      "Epoch 43/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 3.9286e-04 - accuracy: 1.0000 - val_loss: 0.7421 - val_accuracy: 0.8304\n",
      "Epoch 44/100\n",
      "1792/1792 [==============================] - 0s 107us/sample - loss: 3.7108e-04 - accuracy: 1.0000 - val_loss: 0.7442 - val_accuracy: 0.8304\n",
      "Epoch 45/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 3.5929e-04 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.8281\n",
      "Epoch 46/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 3.3164e-04 - accuracy: 1.0000 - val_loss: 0.7514 - val_accuracy: 0.8281\n",
      "Epoch 47/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 3.3388e-04 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.8259\n",
      "Epoch 48/100\n",
      "1792/1792 [==============================] - 0s 103us/sample - loss: 3.2926e-04 - accuracy: 1.0000 - val_loss: 0.7580 - val_accuracy: 0.8259\n",
      "Epoch 49/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 2.7212e-04 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.8281\n",
      "Epoch 50/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 2.7946e-04 - accuracy: 1.0000 - val_loss: 0.7647 - val_accuracy: 0.8281\n",
      "Epoch 51/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 3.3273e-04 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.8304\n",
      "Epoch 52/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 3.8208e-04 - accuracy: 1.0000 - val_loss: 0.7697 - val_accuracy: 0.8281\n",
      "Epoch 53/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 4.3790e-04 - accuracy: 1.0000 - val_loss: 0.7746 - val_accuracy: 0.8237\n",
      "Epoch 54/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 0.0015 - accuracy: 0.9989 - val_loss: 0.7761 - val_accuracy: 0.8237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7730 - val_accuracy: 0.8237\n",
      "Epoch 56/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 8.9433e-04 - accuracy: 0.9994 - val_loss: 0.7849 - val_accuracy: 0.8259\n",
      "Epoch 57/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.7850 - val_accuracy: 0.8259\n",
      "Epoch 58/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 9.6396e-04 - accuracy: 0.9994 - val_loss: 0.7948 - val_accuracy: 0.8259\n",
      "Epoch 59/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 8.0266e-04 - accuracy: 0.9994 - val_loss: 0.7887 - val_accuracy: 0.8214\n",
      "Epoch 60/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 3.0629e-04 - accuracy: 1.0000 - val_loss: 0.7925 - val_accuracy: 0.8259\n",
      "Epoch 61/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 1.5336e-04 - accuracy: 1.0000 - val_loss: 0.7960 - val_accuracy: 0.8259\n",
      "Epoch 62/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 1.3711e-04 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.8259\n",
      "Epoch 63/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 1.3223e-04 - accuracy: 1.0000 - val_loss: 0.8012 - val_accuracy: 0.8259\n",
      "Epoch 64/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 1.2638e-04 - accuracy: 1.0000 - val_loss: 0.8035 - val_accuracy: 0.8259\n",
      "Epoch 65/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 1.1853e-04 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.8259\n",
      "Epoch 66/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 1.1659e-04 - accuracy: 1.0000 - val_loss: 0.8093 - val_accuracy: 0.8259\n",
      "Epoch 67/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 1.1199e-04 - accuracy: 1.0000 - val_loss: 0.8120 - val_accuracy: 0.8259\n",
      "Epoch 68/100\n",
      "1792/1792 [==============================] - 0s 100us/sample - loss: 1.0801e-04 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.8259\n",
      "Epoch 69/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 1.0269e-04 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 0.8259\n",
      "Epoch 70/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 1.0145e-04 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.8259\n",
      "Epoch 71/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 9.5901e-05 - accuracy: 1.0000 - val_loss: 0.8220 - val_accuracy: 0.8259\n",
      "Epoch 72/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 9.4172e-05 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.8259\n",
      "Epoch 73/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 9.3639e-05 - accuracy: 1.0000 - val_loss: 0.8269 - val_accuracy: 0.8259\n",
      "Epoch 74/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 8.9905e-05 - accuracy: 1.0000 - val_loss: 0.8295 - val_accuracy: 0.8259\n",
      "Epoch 75/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 8.5155e-05 - accuracy: 1.0000 - val_loss: 0.8328 - val_accuracy: 0.8259\n",
      "Epoch 76/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 8.2795e-05 - accuracy: 1.0000 - val_loss: 0.8349 - val_accuracy: 0.8259\n",
      "Epoch 77/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 7.7824e-05 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.8259\n",
      "Epoch 78/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 7.6638e-05 - accuracy: 1.0000 - val_loss: 0.8400 - val_accuracy: 0.8259\n",
      "Epoch 79/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 7.2263e-05 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 0.8259\n",
      "Epoch 80/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 7.2028e-05 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.8259\n",
      "Epoch 81/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 6.9140e-05 - accuracy: 1.0000 - val_loss: 0.8474 - val_accuracy: 0.8259\n",
      "Epoch 82/100\n",
      "1792/1792 [==============================] - 0s 99us/sample - loss: 6.8307e-05 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.8259\n",
      "Epoch 83/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 6.4107e-05 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.8259\n",
      "Epoch 84/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 6.2524e-05 - accuracy: 1.0000 - val_loss: 0.8542 - val_accuracy: 0.8259\n",
      "Epoch 85/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 6.1602e-05 - accuracy: 1.0000 - val_loss: 0.8570 - val_accuracy: 0.8259\n",
      "Epoch 86/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 6.0000e-05 - accuracy: 1.0000 - val_loss: 0.8590 - val_accuracy: 0.8259\n",
      "Epoch 87/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 5.7769e-05 - accuracy: 1.0000 - val_loss: 0.8617 - val_accuracy: 0.8259\n",
      "Epoch 88/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 5.5223e-05 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.8259\n",
      "Epoch 89/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 5.2568e-05 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.8259\n",
      "Epoch 90/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 5.1578e-05 - accuracy: 1.0000 - val_loss: 0.8691 - val_accuracy: 0.8259\n",
      "Epoch 91/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 5.2285e-05 - accuracy: 1.0000 - val_loss: 0.8706 - val_accuracy: 0.8259\n",
      "Epoch 92/100\n",
      "1792/1792 [==============================] - 0s 94us/sample - loss: 5.1190e-05 - accuracy: 1.0000 - val_loss: 0.8735 - val_accuracy: 0.8259\n",
      "Epoch 93/100\n",
      "1792/1792 [==============================] - 0s 98us/sample - loss: 4.8035e-05 - accuracy: 1.0000 - val_loss: 0.8759 - val_accuracy: 0.8259\n",
      "Epoch 94/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 4.7583e-05 - accuracy: 1.0000 - val_loss: 0.8778 - val_accuracy: 0.8259\n",
      "Epoch 95/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 4.5551e-05 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.8259\n",
      "Epoch 96/100\n",
      "1792/1792 [==============================] - 0s 97us/sample - loss: 4.3395e-05 - accuracy: 1.0000 - val_loss: 0.8834 - val_accuracy: 0.8259\n",
      "Epoch 97/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 4.3116e-05 - accuracy: 1.0000 - val_loss: 0.8853 - val_accuracy: 0.8259\n",
      "Epoch 98/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 4.2320e-05 - accuracy: 1.0000 - val_loss: 0.8875 - val_accuracy: 0.8259\n",
      "Epoch 99/100\n",
      "1792/1792 [==============================] - 0s 96us/sample - loss: 3.9972e-05 - accuracy: 1.0000 - val_loss: 0.8900 - val_accuracy: 0.8259\n",
      "Epoch 100/100\n",
      "1792/1792 [==============================] - 0s 95us/sample - loss: 3.8975e-05 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.8259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f409b423090>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_converted,y_train_converted,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_teste_converted = tokenizer.texts_to_matrix(x_test,mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c5aab1db0be8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_teste_converted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_teste_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = [np.argmax(predict[i]) for i in range(len(predict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = encode_label.inverse_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_teste_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  bossa nova       0.77      0.86      0.81       223\n",
      "        funk       0.95      0.84      0.89       241\n",
      "      gospel       0.89      0.95      0.92       231\n",
      "   sertanejo       0.81      0.77      0.79       265\n",
      "\n",
      "    accuracy                           0.85       960\n",
      "   macro avg       0.85      0.85      0.85       960\n",
      "weighted avg       0.85      0.85      0.85       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência do Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistência do Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "\n",
    "    pickle.dump(encode_label, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'rb') as handle:\n",
    "\n",
    "    encode_label = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frases de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "funk1 = \"Ela só quer curtir Ela só quer zuar Gosta de dançar Dançar, dançar Se o papo for balada\\nNão deixa pra depois Solteira de carteirinha\"\n",
    "funk2 = \"Eu te amava no tempo da escola Mas você não me dava atenção\\nPedi uma chance, até duas Mas você só me disse não\\nMas você só me disse não Mas você só me disse não Mas com o tempo eu parei e fiz essa canção\\nVou marcar de te ver e não ir\"\n",
    "\n",
    "gospel1 = \"Senhor, meu Deus, quando eu, maravilhado Contemplo a tua imensa criação A terra e o mar e o céu todo estrelado Me vêm falar da tua perfeição Então minh'alma canta a ti\"\n",
    "gospel2 = \" A dor não mata se Deus está presente Só quem caminha com Ele entende o valor De uma lágrima derramada no altar da dor Enxugada pelas mãos do consolador Se Ele quiser, Ele ressuscita mortos\\nEle faz o impossível Tudo porque Ele é Deus Mas se Ele não quer que aconteça do meu jeito Eu declaro que eu aceito\\nE agora o milagre sou eu, sou eu O milagre sou eu, sou eu Eu não vou parar\"\n",
    "\n",
    "sertanejo1 = \"\\nVocê pode ficar com quem você quiser\\nNão tem nada a ver\\nEu não mando em você\\nMas ainda choro\\nE quando alguém comenta não quero saber\\nMe preocupo e apesar dos pesares\\nEu sempre quero te ver bem\\nE ainda vou além\\nEm uma relação\\nSei que não vai ser fácil amar outro alguém\"\n",
    "sertanejo2 = '\\nContando, são 126 cabides\\nE no guarda-roupa, um grande espaço seu\\nDeixado\\nO que faço? Estou eu bem no meu canto\\nFuturo levado meu\\nRoubado\\nTô negociando com a solidão\\nTô tentando convencer que ela não fique, não\\nSe vá\\nTô eu negociando com a solidão\\nSó me cobre esse juros no final da outra estação\\nE se vá\\nEu nem quis te ver de malas prontas\\nLevando o que eu temia\\nSuas roupas e minha alegria\\nE eu nem quis te ver de malas prontas\\nNós dois não mais existe'\n",
    "\n",
    "bossa_nova1 = 'Um cantinho e um violão\\nEste amor, uma canção\\nPra fazer feliz a quem se ama\\nMuita calma pra pensar\\nE ter tempo pra sonhar\\nDa janela vê-se o Corcovado\\nO Redentor que lindo'\n",
    "bossa_nova2 = 'Vai tua vida\\nTeu caminho é de paz e amor\\nA tua vida\\nÉ uma linda canção de amor\\nAbre os teus braços e canta\\nA última esperança\\nA esperança divina\\nDe amar em paz\\nSe todos fossem\\nIguais a você\\nQue maravilha viver\\nUma canção pelo ar\\nUma mulher'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bossa nova'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text_cleaner(bossa_nova1)\n",
    "\n",
    "sample_converted = tokenizer.texts_to_matrix([text],mode='tfidf')\n",
    "\n",
    "predict = model.predict(sample_converted)\n",
    "\n",
    "predict = np.argmax(predict[0])\n",
    "\n",
    "predict = encode_label.inverse_transform([predict])\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have shape (10000,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-18a4b4544ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Senhor, meu Deus, quando eu, maravilhado Contemplo a tua imensa criação A terra e o mar e o céu todo estrelado Me vêm falar da tua perfeição Então minh'alma canta a ti\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwenty_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/eli5/lime/lime.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, doc, predict_proba)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_proba_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m       logging.warning('Network returning invalid probability values. '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m       x, y, sample_weights = standardize_function(\n\u001b[0;32m--> 657\u001b[0;31m           x=x, y=y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     self._internal_adapter = TensorLikeDataAdapter(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    583\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_input to have shape (10000,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "te = TextExplainer(random_state=42)\n",
    "te.fit(\"Senhor, meu Deus, quando eu, maravilhado Contemplo a tua imensa criação A terra e o mar e o céu todo estrelado Me vêm falar da tua perfeição Então minh'alma canta a ti\", model.predict_proba)\n",
    "te.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_tf = LimeTextExplainer(class_names=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d028908ed782>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "exp = explainer_tf.explain_instance([funk1],  model.predict_proba, num_features=4, top_labels=2)\n",
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
